{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Caption Model 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NYdQ9ZZa5K21kkB2jnz5zMznIcrWhk_O",
      "authorship_tag": "ABX9TyMdH68bSLN+TCpWVstvFAWb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaLmZNt1QDBa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.applications import VGG16\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, LSTM, Input, Embedding, Reshape, Concatenate\n",
        "from keras_preprocessing import image\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import string\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import add\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kynLaj-QF91"
      },
      "source": [
        "captions_enc_df = pd.read_csv('/content/drive/My Drive/caption_enc.csv')\n",
        "images_dir = '/content/drive/My Drive/Images'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5dKmauuQWpz"
      },
      "source": [
        "captions_path = '/content/drive/My Drive/captions (1).txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wbhQ15gRA3C"
      },
      "source": [
        "captions_df = pd.read_csv(captions_path)\n",
        "images_list = captions_df['image']\n",
        "captions_list = captions_df['caption']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWCAh6zK7ex-",
        "outputId": "82821f09-09c7-4bef-9bdc-283b5096b5a9"
      },
      "source": [
        "vgg16 = VGG16(include_top = True, weights='imagenet', input_shape=(224,224,3))\n",
        "vgg16 = Model(inputs=vgg16.inputs, outputs=vgg16.layers[-2].output)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1E-A2st8X9l"
      },
      "source": [
        "encoding_dict = {}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njWWra_37gmE",
        "outputId": "6ef82370-7c24-4045-b4e4-ed9a917253fa"
      },
      "source": [
        "images = os.listdir(images_dir)\n",
        "\n",
        "for i in range(len(images)):\n",
        "  img_path = images_dir + '/' + images[i]\n",
        "  img = image.load_img(img_path, target_size=(224,224))\n",
        "  img = image.img_to_array(img)\n",
        "\n",
        "  img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
        "\n",
        "  img_arr = preprocess_input(img_arr)\n",
        "\n",
        "  encoding = vgg16.predict(img_arr)\n",
        "  encoding_dict[images[i]] = encoding\n",
        "  \n",
        "  if(i%200 == 0):\n",
        "    print(str(i) + ' Images encoded')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Images encoded\n",
            "200 Images encoded\n",
            "400 Images encoded\n",
            "600 Images encoded\n",
            "800 Images encoded\n",
            "1000 Images encoded\n",
            "1200 Images encoded\n",
            "1400 Images encoded\n",
            "1600 Images encoded\n",
            "1800 Images encoded\n",
            "2000 Images encoded\n",
            "2200 Images encoded\n",
            "2400 Images encoded\n",
            "2600 Images encoded\n",
            "2800 Images encoded\n",
            "3000 Images encoded\n",
            "3200 Images encoded\n",
            "3400 Images encoded\n",
            "3600 Images encoded\n",
            "3800 Images encoded\n",
            "4000 Images encoded\n",
            "4200 Images encoded\n",
            "4400 Images encoded\n",
            "4600 Images encoded\n",
            "4800 Images encoded\n",
            "5000 Images encoded\n",
            "5200 Images encoded\n",
            "5400 Images encoded\n",
            "5600 Images encoded\n",
            "5800 Images encoded\n",
            "6000 Images encoded\n",
            "6200 Images encoded\n",
            "6400 Images encoded\n",
            "6600 Images encoded\n",
            "6800 Images encoded\n",
            "7000 Images encoded\n",
            "7200 Images encoded\n",
            "7400 Images encoded\n",
            "7600 Images encoded\n",
            "7800 Images encoded\n",
            "8000 Images encoded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6vD41eOFGU"
      },
      "source": [
        "try:\n",
        "  encoding_file = open('/content/drive/My Drive/encoding_dict.pkl','wb')\n",
        "  pickle.dump(encoding_dict, encoding_file)\n",
        "  encoding_file.close()\n",
        "except:\n",
        "  print(\"Something went wrong\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABpKpDfFUYqb"
      },
      "source": [
        "with open('/content/drive/My Drive/encoding_dict.pkl', 'rb') as f:\n",
        "    encoding_dict = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLXiIWzdO-EZ",
        "outputId": "62d3f123-02e3-4286-816e-37731a417db1"
      },
      "source": [
        "encoding_dict['997722733_0cb5439472.jpg']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.       , 0.       , 0.9586386, ..., 0.       , 0.       ,\n",
              "        0.       ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEWpX16tRFq9"
      },
      "source": [
        "all_encodings = []\n",
        "for j in range(len(images_list)):\n",
        "  for i in range(len(images)):\n",
        "    if (images_list[j] == images[i]):\n",
        "     all_encodings.append(encoding_dict[images[i]])\n",
        "\n",
        "captions_df['encodings'] = all_encodings"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "poyft9wTO6UB",
        "outputId": "5defd966-a0dc-43eb-b7ba-c1b88857082a"
      },
      "source": [
        "captions_df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>encodings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set o...</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40450</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A man in a pink shirt climbs a rock face</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40451</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A man is rock climbing high in the air .</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40452</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A person in a red shirt climbing up a rock fac...</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40453</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A rock climber in a red shirt .</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40454</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>A rock climber practices on a rock climbing wa...</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40455 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           image  ...                                          encodings\n",
              "0      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "1      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "2      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "3      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "4      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "...                          ...  ...                                                ...\n",
              "40450   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "40451   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "40452   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "40453   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "40454   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "\n",
              "[40455 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2KLwMiDRUj7"
      },
      "source": [
        "def clean_captions(captions_list):\n",
        "  clean_captions = []\n",
        "  \n",
        "  for i in range(len(captions_list)):\n",
        "    captions_list[i] = captions_list[i].lower()\n",
        "    captions_list[i] = captions_list[i].replace('.','')\n",
        "    words = captions_list[i].split()\n",
        "\n",
        "    words = [word for word in words if len(word)>1]\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    captions_list[i] = ' '.join(words)\n",
        "\n",
        "    captions_list[i] = captions_list[i].replace('[{}]'.format(string.punctuation), ' ')\n",
        "\n",
        "    clean_captions.append(captions_list[i])\n",
        "\n",
        "    \n",
        "\n",
        "  return clean_captions\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "M6q7Qp1CRjXu",
        "outputId": "32ef194b-7463-4222-ef8f-a518ecd3f0cd"
      },
      "source": [
        "captions_enc_df.drop('encodings', axis=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>clean_captions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>child in pink dress is climbing up set of stai...</td>\n",
              "      <td>startseq child in pink dress is climbing up se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>girl going into wooden building</td>\n",
              "      <td>startseq girl going into wooden building endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl climbing into wooden playhouse</td>\n",
              "      <td>startseq little girl climbing into wooden play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl climbing the stairs to her playhouse</td>\n",
              "      <td>startseq little girl climbing the stairs to he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl in pink dress going into wooden cabin</td>\n",
              "      <td>startseq little girl in pink dress going into ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40450</th>\n",
              "      <td>40450</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>man in pink shirt climbs rock face</td>\n",
              "      <td>startseq man in pink shirt climbs rock face en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40451</th>\n",
              "      <td>40451</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>man is rock climbing high in the air</td>\n",
              "      <td>startseq man is rock climbing high in the air ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40452</th>\n",
              "      <td>40452</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>person in red shirt climbing up rock face cove...</td>\n",
              "      <td>startseq person in red shirt climbing up rock ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40453</th>\n",
              "      <td>40453</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>rock climber in red shirt</td>\n",
              "      <td>startseq rock climber in red shirt endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40454</th>\n",
              "      <td>40454</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>rock climber practices on rock climbing wall</td>\n",
              "      <td>startseq rock climber practices on rock climbi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40455 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                     clean_captions\n",
              "0               0  ...  startseq child in pink dress is climbing up se...\n",
              "1               1  ...    startseq girl going into wooden building endseq\n",
              "2               2  ...  startseq little girl climbing into wooden play...\n",
              "3               3  ...  startseq little girl climbing the stairs to he...\n",
              "4               4  ...  startseq little girl in pink dress going into ...\n",
              "...           ...  ...                                                ...\n",
              "40450       40450  ...  startseq man in pink shirt climbs rock face en...\n",
              "40451       40451  ...  startseq man is rock climbing high in the air ...\n",
              "40452       40452  ...  startseq person in red shirt climbing up rock ...\n",
              "40453       40453  ...          startseq rock climber in red shirt endseq\n",
              "40454       40454  ...  startseq rock climber practices on rock climbi...\n",
              "\n",
              "[40455 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XWlE9ZZ5sb"
      },
      "source": [
        "all_encodings = np.load('/content/drive/My Drive/encodings_2.npy')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTDFsmlWWHJI"
      },
      "source": [
        "captions_enc_df['encodings'] = list(all_encodings)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "ZiEXps_SZiNL",
        "outputId": "6ad2c735-3dc9-4f0f-ff88-964b74f2853e"
      },
      "source": [
        "captions_enc_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>encodings</th>\n",
              "      <th>clean_captions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>child in pink dress is climbing up set of stai...</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "      <td>startseq child in pink dress is climbing up se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>girl going into wooden building</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "      <td>startseq girl going into wooden building endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl climbing into wooden playhouse</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "      <td>startseq little girl climbing into wooden play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl climbing the stairs to her playhouse</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "      <td>startseq little girl climbing the stairs to he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>little girl in pink dress going into wooden cabin</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "      <td>startseq little girl in pink dress going into ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40450</th>\n",
              "      <td>40450</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>man in pink shirt climbs rock face</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "      <td>startseq man in pink shirt climbs rock face en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40451</th>\n",
              "      <td>40451</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>man is rock climbing high in the air</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "      <td>startseq man is rock climbing high in the air ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40452</th>\n",
              "      <td>40452</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>person in red shirt climbing up rock face cove...</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "      <td>startseq person in red shirt climbing up rock ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40453</th>\n",
              "      <td>40453</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>rock climber in red shirt</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "      <td>startseq rock climber in red shirt endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40454</th>\n",
              "      <td>40454</td>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>rock climber practices on rock climbing wall</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "      <td>startseq rock climber practices on rock climbi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40455 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                     clean_captions\n",
              "0               0  ...  startseq child in pink dress is climbing up se...\n",
              "1               1  ...    startseq girl going into wooden building endseq\n",
              "2               2  ...  startseq little girl climbing into wooden play...\n",
              "3               3  ...  startseq little girl climbing the stairs to he...\n",
              "4               4  ...  startseq little girl in pink dress going into ...\n",
              "...           ...  ...                                                ...\n",
              "40450       40450  ...  startseq man in pink shirt climbs rock face en...\n",
              "40451       40451  ...  startseq man is rock climbing high in the air ...\n",
              "40452       40452  ...  startseq person in red shirt climbing up rock ...\n",
              "40453       40453  ...          startseq rock climber in red shirt endseq\n",
              "40454       40454  ...  startseq rock climber practices on rock climbi...\n",
              "\n",
              "[40455 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la1dFFCaWsTm"
      },
      "source": [
        "captions_list = captions_enc_df['clean_captions']\n",
        "encodings_list = captions_enc_df['encodings']\n",
        "img_list = captions_enc_df['image']\n",
        "captions =[]\n",
        "encodings = []\n",
        "imgs = []\n",
        "for i in range(len(all_encodings)):\n",
        "  if(i%5 == 0):\n",
        "    captions.append(captions_list[i])\n",
        "    captions.append(captions_list[i+1])\n",
        "    encodings.append(encodings_list[i])\n",
        "    encodings.append(encodings_list[i+1])\n",
        "    imgs.append(img_list[i])\n",
        "    imgs.append(img_list[i+1])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5-TYh-lYeQ8"
      },
      "source": [
        "captions_enc_mod = pd.DataFrame()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LO8TCvLZL5R"
      },
      "source": [
        "captions_enc_mod['images'] = imgs\n",
        "captions_enc_mod['captions'] = captions\n",
        "captions_enc_mod['encodings'] = encodings"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "hDScHrHhZXLy",
        "outputId": "f5dd33c7-ba54-48a7-b3ce-02b615a5bdf6"
      },
      "source": [
        "captions_enc_mod"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>captions</th>\n",
              "      <th>encodings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>startseq child in pink dress is climbing up se...</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>startseq girl going into wooden building endseq</td>\n",
              "      <td>[[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1001773457_577c3a7d70.jpg</td>\n",
              "      <td>startseq black dog and spotted dog are fightin...</td>\n",
              "      <td>[[0.0, 0.0, 0.49410847, 0.0, 0.0, 0.0, 0.0, 1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1001773457_577c3a7d70.jpg</td>\n",
              "      <td>startseq black dog and dog playing with each o...</td>\n",
              "      <td>[[0.0, 0.0, 0.49410847, 0.0, 0.0, 0.0, 0.0, 1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1002674143_1b742ab4b8.jpg</td>\n",
              "      <td>startseq little girl covered in paint sits in ...</td>\n",
              "      <td>[[1.4937079, 0.0, 0.53568363, 0.0, 6.0624743, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16177</th>\n",
              "      <td>99679241_adc853a5c0.jpg</td>\n",
              "      <td>startseq large bird stands in the water on the...</td>\n",
              "      <td>[[0.0, 3.1392221, 0.0, 0.8304528, 0.11121237, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16178</th>\n",
              "      <td>997338199_7343367d7f.jpg</td>\n",
              "      <td>startseq person stands near golden walls endseq</td>\n",
              "      <td>[[2.3300762, 0.0, 0.0, 0.0, 5.3226986, 1.72874...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16179</th>\n",
              "      <td>997338199_7343367d7f.jpg</td>\n",
              "      <td>startseq woman behind scrolled wall is writing...</td>\n",
              "      <td>[[2.3300762, 0.0, 0.0, 0.0, 5.3226986, 1.72874...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16180</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>startseq man in pink shirt climbs rock face en...</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16181</th>\n",
              "      <td>997722733_0cb5439472.jpg</td>\n",
              "      <td>startseq man is rock climbing high in the air ...</td>\n",
              "      <td>[[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16182 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          images  ...                                          encodings\n",
              "0      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "1      1000268201_693b08cb0e.jpg  ...  [[2.507647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15...\n",
              "2      1001773457_577c3a7d70.jpg  ...  [[0.0, 0.0, 0.49410847, 0.0, 0.0, 0.0, 0.0, 1....\n",
              "3      1001773457_577c3a7d70.jpg  ...  [[0.0, 0.0, 0.49410847, 0.0, 0.0, 0.0, 0.0, 1....\n",
              "4      1002674143_1b742ab4b8.jpg  ...  [[1.4937079, 0.0, 0.53568363, 0.0, 6.0624743, ...\n",
              "...                          ...  ...                                                ...\n",
              "16177    99679241_adc853a5c0.jpg  ...  [[0.0, 3.1392221, 0.0, 0.8304528, 0.11121237, ...\n",
              "16178   997338199_7343367d7f.jpg  ...  [[2.3300762, 0.0, 0.0, 0.0, 5.3226986, 1.72874...\n",
              "16179   997338199_7343367d7f.jpg  ...  [[2.3300762, 0.0, 0.0, 0.0, 5.3226986, 1.72874...\n",
              "16180   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "16181   997722733_0cb5439472.jpg  ...  [[0.0, 0.0, 0.9586386, 0.0, 0.87273586, 1.9431...\n",
              "\n",
              "[16182 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNcgVgIiaVmh"
      },
      "source": [
        "train_imgs = imgs[0:13000]\n",
        "train_encodings = encodings[0:13000]\n",
        "train_captions = captions[0:13000]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyik-MHhouRc"
      },
      "source": [
        "test_imgs = imgs[13001:]\n",
        "test_encodings = encodings[13001:]\n",
        "test_captions = captions[13001:]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmHxanUa0lf"
      },
      "source": [
        "def to_tokenize(train_captions):\n",
        "\n",
        "\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(train_captions)\n",
        "\n",
        "  return tokenizer\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXWootJoa6lg"
      },
      "source": [
        "tokenizer = to_tokenize(train_captions)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qqFrtYMbKQN"
      },
      "source": [
        "maxLen = max(len(des.split()) for des in train_captions)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBL9R16lbPog"
      },
      "source": [
        "def create_sequences(tokenize, max_length, captions, encodings, vocab_size):\n",
        "  X1, X2, y = list(), list(), list()\n",
        "\n",
        "  for encoding, caption in zip(encodings, captions):\n",
        "\n",
        "    cap = tokenize.texts_to_sequences([caption])[0]\n",
        "\n",
        "    for i in range(1,len(cap)):\n",
        "\n",
        "      in_seq, out_seq = cap[:i], cap[i]\n",
        "\n",
        "      in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\n",
        "      out_seq = to_categorical([out_seq],num_classes=vocab_size)[0]\n",
        "\n",
        "      \n",
        "\n",
        "      X1.append(encoding)\n",
        "      X2.append(in_seq)\n",
        "      y.append(out_seq)\n",
        "  return np.array(X1), np.array(X2), np.array(y)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_9VkTE7bXPY"
      },
      "source": [
        "X1_train, X2_train, y_train = create_sequences(tokenizer, maxLen, train_captions, train_encodings, vocab_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9wHY4Uto54i"
      },
      "source": [
        "X1_test, X2_test, y_test = create_sequences(tokenizer, maxLen, test_captions, test_encodings, vocab_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtJLVNoebx41"
      },
      "source": [
        "np.save('/content/drive/My Drive/encodings_2.npy', np.array(all_encodings))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SZbXEoxcvfN",
        "outputId": "8583d7b5-bcc4-4860-d19b-5e692bded97d"
      },
      "source": [
        "X1_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131868, 1, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rilUFToBAkMd",
        "outputId": "e6a9ba19-7e2e-43ff-d4de-6904e2e351a1"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131868, 5306)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEN6XgIMdJrB"
      },
      "source": [
        "def caption_model(vocab_size, maxLen):\n",
        "\n",
        "  input_1 = Input(shape=(1,4096))\n",
        "  fe_2 = Dense(256, activation='relu')(input_1)\n",
        "\n",
        "  input_2 = Input((maxLen,))\n",
        "\n",
        "  emb = Embedding(vocab_size, 300, mask_zero=True)(input_2)\n",
        "  emb2 = LSTM(256)(emb)\n",
        "  res = Reshape((1,256))(emb2)\n",
        "\n",
        "  decoder1 = Concatenate()([fe_2,res])\n",
        "  decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "  output = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "  output = Reshape((vocab_size,))(output)\n",
        "\n",
        "  model = Model(inputs = [input_1, input_2], outputs=output)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqOA1lnLjKGl"
      },
      "source": [
        "model = caption_model(vocab_size, maxLen)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh8lTTdzjcJB",
        "outputId": "e0befdb6-1624-4ccc-8f1e-92b88ed8a550"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 31, 300)      1591800     input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1, 4096)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 256)          570368      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1, 256)       1048832     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 256)       0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 512)       0           dense_6[0][0]                    \n",
            "                                                                 reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 256)       131328      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1, 5306)      1363642     dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 5306)         0           dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,705,970\n",
            "Trainable params: 4,705,970\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXscihW1jeyB"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gcLDVkjl16",
        "outputId": "558478f5-12ce-4b5b-8951-0ffaae865713"
      },
      "source": [
        "model.fit([X1_train,X2_train], y_train, epochs=50, batch_size=64, validation_data=([X1_test, X2_test],y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2061/2061 [==============================] - 196s 95ms/step - loss: 5.2785 - accuracy: 0.1517 - val_loss: 4.7411 - val_accuracy: 0.1913\n",
            "Epoch 2/50\n",
            "2061/2061 [==============================] - 193s 94ms/step - loss: 4.3450 - accuracy: 0.2286 - val_loss: 4.2750 - val_accuracy: 0.2327\n",
            "Epoch 3/50\n",
            "2061/2061 [==============================] - 193s 94ms/step - loss: 3.8427 - accuracy: 0.2717 - val_loss: 4.0832 - val_accuracy: 0.2553\n",
            "Epoch 4/50\n",
            "2061/2061 [==============================] - 191s 93ms/step - loss: 3.4775 - accuracy: 0.3040 - val_loss: 4.0083 - val_accuracy: 0.2677\n",
            "Epoch 5/50\n",
            "2061/2061 [==============================] - 190s 92ms/step - loss: 3.1666 - accuracy: 0.3315 - val_loss: 3.9908 - val_accuracy: 0.2750\n",
            "Epoch 6/50\n",
            "2061/2061 [==============================] - 190s 92ms/step - loss: 2.8959 - accuracy: 0.3565 - val_loss: 4.0276 - val_accuracy: 0.2777\n",
            "Epoch 7/50\n",
            "2061/2061 [==============================] - 191s 92ms/step - loss: 2.6686 - accuracy: 0.3804 - val_loss: 4.0451 - val_accuracy: 0.2749\n",
            "Epoch 8/50\n",
            "2061/2061 [==============================] - 192s 93ms/step - loss: 2.4823 - accuracy: 0.4050 - val_loss: 4.0947 - val_accuracy: 0.2797\n",
            "Epoch 9/50\n",
            " 524/2061 [======>.......................] - ETA: 2:19 - loss: 2.2881 - accuracy: 0.4363"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "2TXhoCVRjrch",
        "outputId": "45092b98-7e1f-4900-9d70-44a2a97ee92d"
      },
      "source": [
        "model.save_weights('/content/drive/My Drive/caption_weights2.hdf5')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-ea91cd7036a8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model.save_weights(/\\'content/drive/My Drive/caption_weights2.hdf5')\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieVY8G2OF4nO"
      },
      "source": [
        "model.fit([X1_train,X2_train], y_train, epochs=20, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8jHhMKFF8XV"
      },
      "source": [
        "model.save_weights(/\\'content/drive/My Drive/caption_weights3.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQOJhEIueF40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}